{% extends "base.html" %}
{% load static %}
{% block title %}About{% endblock %}

{% block style %}
{% endblock %}

{% block index %}
{% endblock %}  

{% block content %}

<section class="about_section layout_padding ">
  <div class="container">
    <div class="row">
      <div class="col-md-12">
        <div class="detail-box">
          <div class="heading_container">
            <h2>About the Credit Card Fraud Detection Project</h2>
          </div>
          <p>
            This project is based on the Credit Card Fraud Detection dataset from Kaggle, which can be found <a href="https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud" target="_blank" style="background-color: transparent;border: transparent;color: blue;padding: 0%;margin: 0%;">here</a>. The dataset contains transactions made by European cardholders during September 2013, with a total of 284,807 transactions and 492 fraudulent transactions, making this a highly imbalanced dataset.
          </p>

          <h3>Understanding the Dataset</h3>
          <p>
            The dataset consists of 31 columns, including features and a target variable. The features (V1 to V28) are the result of a Principal Component Analysis (PCA) to protect sensitive information. Here are the key variables:
          </p>
          <ul>
            <li><strong>V1 to V28:</strong> These are the principal components obtained from applying PCA on the original transaction data. The actual features used for these transformations are not disclosed for privacy reasons.</li>
            <li><strong>Time:</strong> This field contains the time elapsed between this transaction and the first transaction in the dataset, measured in seconds. It helps capture trends over time.</li>
            <li><strong>Amount:</strong> The transaction amount for each record. This variable can be useful for detecting anomalies in fraudulent transactions.</li>
            <li><strong>Class:</strong> This is the target variable that indicates whether a transaction is fraudulent. A value of 1 represents fraud, while 0 represents a legitimate transaction.</li>
          </ul>

          <p>
            Since the dataset is highly imbalanced, with only 492 fraud cases out of 284,807 total transactions, special techniques such as SMOTE (Synthetic Minority Over-sampling Technique) were used to handle this imbalance during the training phase.
          </p>

          <h3>Model Training with XGBoost Classifier</h3>
          <p>
            The following XGBoost Classifier model was trained on the dataset using SMOTE to handle the class imbalance.
          </p>
          <pre>
# 9. Train XGBoost Classifier
print("\nTraining the XGBoost classifier...")
model = xgb.XGBClassifier(
    n_estimators=100,
    max_depth=5,
    learning_rate=0.1,
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42
)
model.fit(X_train_smote, y_train_smote)
print("Model training completed.")
          </pre>

          <h3>Model Evaluation</h3>
          <p>
            The trained model was evaluated on a test dataset, yielding the following performance metrics:
          </p>
          <pre>
# 10. Model Evaluation
print("\nEvaluating the model on the test set...")
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)

# Accuracy
accuracy = accuracy_score(y_test, y_pred)

# F1 Score
f1 = f1_score(y_test, y_pred)

# Recall
recall = recall_score(y_test, y_pred)

# Precision
precision = precision_score(y_test, y_pred)

# Log Loss
loss = log_loss(y_test, y_pred_proba)

# Print Metrics
print(f"\nAccuracy: {accuracy:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"Recall: {recall:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Log Loss: {loss:.4f}")
          </pre>

          <h3>Results</h3>
          <p>
            Here are the key results of the evaluation:
          </p>
          <pre>
Accuracy: 0.9951
F1 Score: 0.3735
Recall: 0.8378
Precision: 0.2403
Log Loss: 0.0210
          </pre>

          <h3>Classification Report and Confusion Matrix</h3>
          <pre>
Classification Report:
               precision    recall  f1-score   support

           0       1.00      1.00      1.00     85295
           1       0.24      0.84      0.37       148

    accuracy                           1.00     85443
   macro avg       0.62      0.92      0.69     85443
weighted avg       1.00      1.00      1.00     85443

Confusion Matrix:
 [[84903   392]
 [   24   124]]
          </pre>
        </div>
      </div>
    </div>
  </div>
</section>

{% endblock %}

{% block footer %}
{% endblock %}
